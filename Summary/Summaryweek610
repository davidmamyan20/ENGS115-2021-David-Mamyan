27.09.2021

In today's lecture, we discussed the results of the quiz. First to remember, a concept is a set of types which conform the concept requirements. The requirements of a container concept are elements. The complexity of the access() function defined in the random access container, which returns an element of the container at the given position, is a constant. The complexity of a function where there are two different sizes like for example i<n and j<m, then the complexity is O(mn). We implemented a C code, where there is a list with its start being null and size being 0, adn also implemeneted another size, so we used a for loop, where i = 0 only works, because there is a code assert (i==0), which means the loop is gonna work for only 0, in case of others it will abort. SO simply after that we define l->start  by n, then check if the previous is NULL, so if it doesn't prev->next becomes n, then we define prev by n, and give ++ to l->size.

29.09.2021

Today our lecture was about algorithms. Algorithms can't go back in single linked texts, but it can do in double linked list. Regular basic operations that we are going to discuss about are insertion, deletion, display, search, delete and reverse. Deletion deletes an element at the beginning of the list, delete deletes an element using given key. Reverse - reverses the list. Search - searches an element using the given key. Insertion - adds an element at the beginning of the list. Display - displays the complete list. In the doubly linked list the previous element of the first one is NULL, and the next element of the last one is also NULL. Another version of a linked list, which is rarely used is the Doubly Circular Linked List, where the previous element of the first one, and the next element of the last one are circular. In other words Prev 1st element is the next element of the last one, and also the previous element of the first one is the previous element of the last one. So the topic we talked about today is the search option. Mainly we used examples of searching an element in the ordered list, if the search(n) = n, then return. If it is smaller it srats to look for the bigger ones, if it is big, it starts looking for smaller ones. 1.) n   2.) n/2 3) n/4 4.) n/8 5.) n/16. .... log2n.

01.10.21

In today's lecture we started discussing different ways of sorting, which we were required to watch videos about it. We start with the selection sort. It chooses the current minimum, and compares with the current element of the array, if it's bigger than the minimum, their positions won't be swapped, if it's smaller than the minimum, their positions will swap. We use the first element for comparison, and when it is sorted, next time the loop works it will ignore the first element, and go to the next one. And after the first comparision current position and i, which is also a position of an array ++. About the bubble code which compare A[i] and A[i+1], and it will swap if A[i]>A[i+1], and the loop will be repeated again, unless the array is sorted. And every time it runs the last element is ignored, every time. We find the complexity of the bubble sort by adding numbers from 1 to n which is equal to n(n-1)/2, and after droping the constants and n with lower powers, we get O(n^2).

04.10.21

Today, we discussed the complexity of the selection sort, which is equal to n^2, because mathematically we know that the sum of the numbers from 1 to n is equal to n(n-1)/2, which is equal to (n^2-n)/2, so we drop the constants and the n with higher degree, and get O(n^2). Then we discussed the bubble sort, and compared it with the selection sort, in the bubble sort we compare the pairs of element, whereas in the selection sort we compare the current minimum, with the rest of the elements in the array. The insertion sort starts with the left first element, assuming it is in the right position, then compares it with the elements on the right, and if they are smaller, they swap places, in order to determine the correct position of the elements. The complexity of the bubble sort is also (n^2). The complexity of the insertion sort is O(n^2) in the worst case, when the elements are sorted in the reverse order, in other words there will be swaps, after every comparison. We simply calculate it by adding the numbers from 1 to n-1, and get O(n^2). It is not good, when the complexity is O(n^2), because when elements increase by 1, the complexity grows at a faster rate. Merge sort is about the basic of divide and conquer. WE can guess that the complexity is logarithmic because of divide and conquer. After dividing, the part of sticking them together is tricky, in case of two element arrays, it is not hard, but when it comes to making an array of four elements, is tough, we have to find all minimums to fix the position of the element, and the same goes for the rest. This sort is a recursive algorithm. We find the complexity by finding the quanity of the steps of dividing and conquering. In the first step we get n/2 in the second step n/4, so we have to do until n/2^x, in other words there are x steps in this algorithm. n/2^x = 1 x = log2n. The complexity of the divisions in log2n. In the end we know that the complexity is nlogn.  That's all for this class.

06.10.21

Today, we are implementing a selection sort algorithm in an array. First, we need to select the largest item. Secondly, we should swap the largest item with the last item, moving it to the end. Then we ignore the largest last item, then search the rest of the array for the largest item. As we start from 0, our last element is n-1, not n. Then we do an array swap with n-2, because n-1 is fixed. In case if the indexes n and i are the same, then the program will not do the required action, so we need an if(l != i), then swap, in order to make the program work. We must swap the largest item with the last item (next-to-last in the original array), then continue until n-1 items are selected and swapped (the remaining item on the first index). The start of the array is the pointer to the first element of the array. Then we do insertion sort. For the first step we set the Array[0] as the sorted part of the array and Array[1] - Array [n - 1] as not sorted part of the array, then take the first item from the not sorted array and find its proper place in the sorted part.

08.10.21

In todays lecture, we discussed the merge sort. First it divides the array in two parts and starts with returning the first part, we divide it until its 1 element in it, if it's one we return it, then after comparisons we return, but we always start from the first one, then the next one, after we finish with the whole first part, we do the same with the second part. In the pseudocode array is divided in two parts array1 = array[0]......array[n/2], array2 = array[n/2]......array[n]. 


27.10.21

In todays lecture, we started discussing the quick sort algorithm. To start, the quick sort algorithm is choosing a pivot, then moves it to the end, while trying to find the correct element for the pivot. It should make sure that the elements from the left are bigger and the elements from the right are smaller. After the comparissons, the elements which are left from the pivot should be smaller and elements from the right should be bigger than our pivot. Then the pivot will come back to its place, and the same process will be happening with the left and the right parts of the arrays. The middle elements of the array are mainly being chosen as pivots.

29.10.21

In todays lecture, we started the topic about the stack and queue. The stack is a container of objects that are inserted and removed according to the Last-in First-Out principle and stacks are limited access data structures. There are only two operations push and pop, and also element top, push pushes data into a stack and top is just returning the value on the top. A queue is a container of objects that are inserted and removed according to the first-in first-out principle. It's similar to the stack, as there are two operations which are like the stacks, but with one difference, which is the fact that the pop removes the front item and not the one in the back.


